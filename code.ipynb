{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "\n",
    "# 定义全局变量\n",
    "nthresholds = 100  # 在使用前定义\n",
    "\n",
    "# 对于 matplotlib 的内联显示\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "with open(os.path.join(DATA_PATH, \"stopwords.txt\"), 'r') as file:\n",
    "    stopwords = file.read()\n",
    "\n",
    "amazon_df = pd.read_csv(os.path.join(DATA_PATH, \"Amazon.csv\"))\n",
    "google_df = pd.read_csv(os.path.join(DATA_PATH, \"Google.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "# 读取完整映射文件\n",
    "perfectMap_df = pd.read_csv(os.path.join(DATA_PATH, \"Amazon_Google_perfectMapping.csv\"))\n",
    "perfectMap = []\n",
    "\n",
    "def buildPerfectMap(x): \n",
    "    perfectMap.append((x['idAmazon'], x['idGoogleBase']))\n",
    "\n",
    "perfectMap_df.apply(buildPerfectMap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords = stopwords.split('\\n')\n",
    "split_regex = r'\\w+'\n",
    "# TODO Implement this\n",
    "\"\"\"\n",
    "一：分割文本，得到有效Tokens\n",
    "题目要求：\n",
    "    读取Amazon.csv和Google.csv中的数据。\n",
    "    对每条数据进行文本分割，得到tokens列表。\n",
    "    读取stopwords.txt，去除停用词。\n",
    "输入：\n",
    "    Amazon.csv文件，Google.csv文件字符串\n",
    "    stopwords.txt文件字符串\n",
    "输出：\n",
    "    Amazon数据集的tokens列表\n",
    "    Google数据集的tokens列表\n",
    "\"\"\"\n",
    "def simple_tokenize(string):\n",
    "    \"\"\"\n",
    "    简单分词函数，使用正则表达式提取单词\n",
    "    \"\"\"\n",
    "    return re.findall(split_regex, string.lower())\n",
    "\n",
    "def tokenize(string):\n",
    "    \"\"\"\n",
    "    分词并去除停用词\n",
    "    \"\"\"\n",
    "    tokens = simple_tokenize(string)\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "def rec2tok(x, dic):\n",
    "    \"\"\"\n",
    "    将记录转换为tokens并存储在字典中\n",
    "    \"\"\"\n",
    "    # 合并所有相关字段\n",
    "    text = f\"{x['title']} {x['description']}\"\n",
    "    tokens = tokenize(text)\n",
    "    dic[x['id']] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO Implement this\n",
    "\"\"\"\n",
    "二：求解TF,IDF,TF-IDF\n",
    "题目要求：\n",
    "    对每个数据集的tokens计算TF值。\n",
    "    计算IDF值。\n",
    "    根据TF和IDF计算TF-IDF。\n",
    "输入：\n",
    "    数据集的tokens列表\n",
    "输出：\n",
    "    数据集的TF-IDF字典\n",
    "\"\"\"\n",
    "def inc(i, dic):\n",
    "    \"\"\"\n",
    "    增加字典中键i的计数\n",
    "    \"\"\"\n",
    "    if i in dic:\n",
    "        dic[i] += 1\n",
    "    else:\n",
    "        dic[i] = 1\n",
    "\n",
    "def tf(tokens):\n",
    "    \"\"\"\n",
    "    计算词频(TF)\n",
    "    \"\"\"\n",
    "    tf_dict = {}\n",
    "    for token in tokens:\n",
    "        inc(token, tf_dict)\n",
    "    return tf_dict\n",
    "\n",
    "def idf(rec2tok):\n",
    "    \"\"\"\n",
    "    计算逆文档频率(IDF)\n",
    "    \"\"\"\n",
    "    idf_dict = {}\n",
    "    N = len(rec2tok)  # 文档总数\n",
    "    \n",
    "    # 统计每个词出现在多少文档中\n",
    "    for doc_id in rec2tok:\n",
    "        seen = set()  # 用于去重\n",
    "        for token in rec2tok[doc_id]:\n",
    "            if token not in seen:\n",
    "                inc(token, idf_dict)\n",
    "                seen.add(token)\n",
    "    \n",
    "    # 计算IDF值\n",
    "    for token in idf_dict:\n",
    "        idf_dict[token] = math.log(N / idf_dict[token])\n",
    "    \n",
    "    return idf_dict\n",
    "\n",
    "def tfidf(tokens, idfs):\n",
    "    \"\"\"\n",
    "    计算TF-IDF值\n",
    "    \"\"\"\n",
    "    tfidf_dict = {}\n",
    "    tf_dict = tf(tokens)\n",
    "    \n",
    "    for token in tf_dict:\n",
    "        if token in idfs:\n",
    "            tfidf_dict[token] = tf_dict[token] * idfs[token]\n",
    "            \n",
    "    return tfidf_dict\n",
    "# TODO Implement this\n",
    "\"\"\"\n",
    "三：构建token与ID的逆向索引\n",
    "题目要求：\n",
    "    构建数据集的逆向索引。\n",
    "输入：\n",
    "    数据集的tokens列表\n",
    "输出：\n",
    "    数据集的逆向索引字典\n",
    "\"\"\"\n",
    "def invertIndex(forward_index):\n",
    "    \"\"\"\n",
    "    构建倒排索引\n",
    "    \"\"\"\n",
    "    inverted_index = {}\n",
    "    for doc_id in forward_index:\n",
    "        for token in set(forward_index[doc_id]):  # 使用set去重\n",
    "            if token not in inverted_index:\n",
    "                inverted_index[token] = []\n",
    "            inverted_index[token].append(doc_id)\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# TODO Implement this\n",
    "\"\"\"\n",
    "四：题目要求：实现向量间点积方法\n",
    "    输入：向量a与向量b\n",
    "    输出：a和b点积的结果\n",
    "\"\"\"\n",
    "def dotprod(a, b):\n",
    "    \"\"\"\n",
    "    优化的向量点积计算\n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    # 只考虑较重要的tokens（TF-IDF值较高的）\n",
    "    threshold = 0.1  # 设置一个阈值来过滤低权重的tokens\n",
    "    for key in a:\n",
    "        if key in b and a[key] > threshold and b[key] > threshold:\n",
    "            sum += a[key] * b[key]\n",
    "    return sum\n",
    "\n",
    "def norm(a):\n",
    "    \"\"\"\n",
    "    计算向量的模长\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum(x*x for x in a.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "amazon_rec2tok = {}\n",
    "google_rec2tok = {}\n",
    "\n",
    "amazon_df.apply(lambda x:rec2tok(x,amazon_rec2tok),axis=1)\n",
    "google_df.apply(lambda x:rec2tok(x,google_rec2tok),axis=1)\n",
    "\n",
    "amazon_inv=invertIndex(amazon_rec2tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "idfs_full = dict(Counter(idf(amazon_rec2tok))+Counter(idf(google_rec2tok)))\n",
    "google_weights={i:tfidf(google_rec2tok[i],idfs_full) for i in google_rec2tok}\n",
    "amazon_weights={i:tfidf(amazon_rec2tok[i],idfs_full) for i in amazon_rec2tok}\n",
    "google_norm={i:norm(google_weights[i]) for i in google_weights}\n",
    "amazon_norm={i:norm(amazon_weights[i]) for i in amazon_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def buildSim(Id, weight, norm, weights, norms, inv, sims):\n",
    "    \"\"\"\n",
    "    构建相似度\n",
    "    \"\"\"\n",
    "    for i in weight:\n",
    "        if i in inv:\n",
    "            for j in inv[i]:\n",
    "                if not (j,Id) in sims:\n",
    "                    # 确保分母不为0\n",
    "                    if norm == 0 or norms[j] == 0:\n",
    "                        continue\n",
    "                    # 计算余弦相似度\n",
    "                    similarity = dotprod(weight, weights[j]) / (norm * norms[j])\n",
    "                    # 确保相似度在[0,1]范围内\n",
    "                    similarity = max(0, min(1, similarity))\n",
    "                    sims[(j,Id)] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sims={}\n",
    "for i in google_weights:\n",
    "    buildSim(i,google_weights[i],google_norm[i],amazon_weights,amazon_norm,amazon_inv,sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "true_dup_sims = []\n",
    "def truepos(threshold):\n",
    "    global true_dup_sims\n",
    "    true_dup_sims=[]\n",
    "    for i in sims:\n",
    "        if sims[i]>threshold: \n",
    "            true_dup_sims.append(i)\n",
    "def bin(similarity):\n",
    "    return int(similarity * nthresholds)\n",
    "\n",
    "# TODO Implement this\n",
    "def falsepos(threshold):\n",
    "    ans=0\n",
    "    for i in true_dup_sims:\n",
    "        if not i in perfectMap: ans+=1\n",
    "    return ans\n",
    "# TODO Implement this (returns a float)\n",
    "def precision(threshold):\n",
    "    truepos(threshold)\n",
    "    true_positives = len(true_dup_sims) - falsepos(threshold)\n",
    "    total_predictions = len(true_dup_sims) if len(true_dup_sims) > 0 else 1\n",
    "    return true_positives / total_predictions\n",
    "\n",
    "\n",
    "thresholds = [float(n) / nthresholds for n in range(0, nthresholds)]  # 调整范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "p=[precision(n) for n in thresholds]\n",
    "\n",
    "\n",
    "# 在这里添加调试代码\n",
    "threshold = 0.84\n",
    "truepos(threshold)\n",
    "print(f\"阈值{threshold}时的匹配对数量：\", len(true_dup_sims))\n",
    "print(f\"其中错误匹配数量：\", falsepos(threshold))\n",
    "\n",
    "threshold = 0.85\n",
    "truepos(threshold)\n",
    "print(f\"阈值{threshold}时的匹配对数量：\", len(true_dup_sims))\n",
    "print(f\"其中错误匹配数量：\", falsepos(threshold))\n",
    "\n",
    "# 继续原有的绘图代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 替换 %pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, p)\n",
    "plt.grid(True)\n",
    "plt.xlabel('阈值')\n",
    "plt.ylabel('精确率')\n",
    "plt.title('阈值-精确率曲线')\n",
    "\n",
    "# 找出最大精确率及其阈值\n",
    "max_precision_idx = p.index(max(p))\n",
    "print(\"最大精确率：\", max(p))\n",
    "print(\"最大精确率阈值：\", thresholds[max_precision_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
